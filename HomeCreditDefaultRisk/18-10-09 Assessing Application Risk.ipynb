{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Application Risk\n",
    "\n",
    "<span>This notebook details an approach to deal with Home Credit Default Risk Competion. The goal of the competition is to identify the amount of risk Home Credit undertakes when given out a loan to a client who does not have a credit history. The goal of the machine learning algorithim is to see client loan application should be rejected or accepted</span>\n",
    "\n",
    "**Dataset:** [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk)\n",
    "\n",
    "#### Scientific Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T06:44:22.395526Z",
     "start_time": "2018-10-10T06:44:17.860745Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.14.5\n",
      "Pandas version: 0.23.4\n",
      "Sklearn version: 0.19.0\n",
      "Keras version: 2.2.4\n",
      "Scipy version: 0.19.1\n",
      "XBG Boost version: 0.72\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Import Modules\n",
    "import datetime\n",
    "import itertools\n",
    "import graphviz\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import xgboost\n",
    "\n",
    "# Other Imports\n",
    "from matplotlib import rcParams, gridspec\n",
    "from scipy import io\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Keras Imports\n",
    "from keras import models, layers\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Scipy Imports\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Preprocesing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sklearn Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC, SVC, OneClassSVM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report,\n",
    "                             f1_score, precision_score, recall_score,\n",
    "                             precision_recall_fscore_support, roc_auc_score)\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import (cross_val_score, KFold, train_test_split,\n",
    "                                     GridSearchCV, cross_validate,\n",
    "                                     StratifiedKFold)\n",
    "\n",
    "\n",
    "# Set Numpy and Python Random Seed\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Pandas Configuration\n",
    "pd.set_option('max_columns', 1000)\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "\n",
    "# Warning Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting Configuration\n",
    "rcParams['figure.figsize'] = (12.0, 4.0)\n",
    "rcParams.update({'font.size': 10})\n",
    "colors = ['#74a9cf', '#6a51a3']\n",
    "\n",
    "# Print versions of each package above \n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Sklearn version: {}\".format(sklearn.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))\n",
    "print(\"Scipy version: {}\".format(scipy.__version__))\n",
    "print(\"XBG Boost version: {}\".format(xgboost.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "\n",
    "There are bunch of different tables within this dataset. I have import those table in a local SQL database. I will be merge the table values to build our training dataset. I created a list of the tablse below\n",
    "\n",
    "\n",
    "train.csv(trdf) - Static Training Data From Applications\n",
    "test.csv(tsdf) - Static Training Data From Applications\n",
    "bureau.csv(budf) - Clients previous credit rating provided by other financial institutions\n",
    "bureau_balance.csv(bbdf) - Bureau Balan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from SQL\n",
    "df = pd.read_sql(\"\"\"\n",
    "                SELECT `Year`,`Stage`,`Home Team Initials`, \n",
    "                `Away Team Initials`, `Home Team Goals`, `Away Team Goals`, \n",
    "                `Half-time Home Goals`, `Half-time Away Goals` FROM Matches;\n",
    "                 \"\"\", engine).dropna(how='any', axis=0)\n",
    "# Some preprocessing on the data\n",
    "df['Year'] = df['Year'].astype(int).astype(str)\n",
    "df['Index'] = df['Home Team Initials'] +' vs '+ df['Away Team Initials'] +' - '+ df['Stage'] +' - ' + df['Year']\n",
    "df = df.set_index(['Index'])\n",
    "df = df.drop(['Year', 'Stage', 'Home Team Initials','Away Team Initials'], axis =1)\n",
    "\n",
    "# View head of your dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import paysim data\n",
    "sdf = read_csv('Data/Synthetic/synthetic.csv')\n",
    "sdf = sdf.rename(columns={'isfraud':'target', 'oldbalanceorg':'oldbalanceorig'})\n",
    "\n",
    "# Create a holdout dataset with 50% of the data. 3 milliion+ rows each.\n",
    "holdout_index = np.random.choice(np.arange(0,sdf.shape[0]), size=int(sdf.shape[0]*0.5),replace=False)\n",
    "sdf_holdout = sdf[sdf.index.isin(holdout_index)]\n",
    "sdf = sdf[~sdf.index.isin(holdout_index)]\n",
    "sdf.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
