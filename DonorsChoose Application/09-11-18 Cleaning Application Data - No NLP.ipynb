{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clearning Data - Non-NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import *\n",
    "\n",
    "test_df = pd.read_csv('Data/test.csv', low_memory=False,\n",
    "                     parse_dates=['project_submitted_datetime'])\n",
    "train_df = pd.read_csv('Data/train.csv', low_memory=False, \n",
    "                       parse_dates=['project_submitted_datetime'])\n",
    "\n",
    "dfs = [test_df, train_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                  0\n",
       "teacher_id                                          0\n",
       "teacher_prefix                                      1\n",
       "school_state                                        0\n",
       "project_submitted_datetime                          0\n",
       "project_grade_category                              0\n",
       "project_subject_categories                          0\n",
       "project_subject_subcategories                       0\n",
       "project_title                                       0\n",
       "project_essay_1                                     0\n",
       "project_essay_2                                     0\n",
       "project_essay_3                                 75331\n",
       "project_essay_4                                 75331\n",
       "project_resource_summary                            0\n",
       "teacher_number_of_previously_posted_projects        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                   0\n",
       "teacher_id                                           0\n",
       "teacher_prefix                                       4\n",
       "school_state                                         0\n",
       "project_submitted_datetime                           0\n",
       "project_grade_category                               0\n",
       "project_subject_categories                           0\n",
       "project_subject_subcategories                        0\n",
       "project_title                                        0\n",
       "project_essay_1                                      0\n",
       "project_essay_2                                      0\n",
       "project_essay_3                                 175706\n",
       "project_essay_4                                 175706\n",
       "project_resource_summary                             0\n",
       "teacher_number_of_previously_posted_projects         0\n",
       "project_is_approved                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place marker for missing teaher prefixes, and projects 3 & 4\n",
    "for df in dfs:\n",
    "    df.teacher_prefix = df.teacher_prefix.fillna(value='No Prefix')\n",
    "    df.project_essay_3 = df.project_essay_3.fillna(value='No Essay')\n",
    "    df.project_essay_4 = df.project_essay_4.fillna(value='No Essay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Categories into Dummy Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_categories(series):\n",
    "    series = series.str.replace(' & ', ' ')\n",
    "    series = series.str.replace(',', '')\n",
    "    series = series.str.replace('The ', '')\n",
    "    series = series.apply(lambda x: x.split())\n",
    "    series = series.apply(lambda x: list(np.unique(x)))\n",
    "    return series\n",
    "\n",
    "def get_dummies_from_series_of_lists(series, column_prefix):\n",
    "    # Creating main dummies output dataframe \n",
    "    subject_categories = list()\n",
    "    for row in tqdm(series):\n",
    "        for value in row:\n",
    "            if value not in subject_categories:\n",
    "                subject_categories.append(value)\n",
    "    dummies = pd.DataFrame(columns=subject_categories)\n",
    "    dummies = dummies.sort_index(1)\n",
    "    \n",
    "    # Append series data to dummies dataframe\n",
    "    for row in tqdm(series):\n",
    "        dummy_row = pd.get_dummies(pd.DataFrame(data=[row]))\n",
    "        for i, value in enumerate(row):\n",
    "            row[i] = column_prefix+row[i]\n",
    "        dummy_row.columns = row\n",
    "        dummy_row = dummy_row.sort_index(1)\n",
    "        dummies = dummies.append(dummy_row)\n",
    "    dummies = dummies.fillna(value=0).reset_index(drop=True)\n",
    "    return dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182080/182080 [00:00<00:00, 1302200.41it/s]\n",
      "100%|██████████| 182080/182080 [3:54:16<00:00,  7.39it/s]\n",
      "100%|██████████| 78035/78035 [00:00<00:00, 1306596.86it/s]\n",
      "100%|██████████| 78035/78035 [46:16<00:00, 28.11it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df.project_subject_categories = clean_categories(train_df.project_subject_categories)\n",
    "train_df_categories_dummies = get_dummies_from_series_of_lists(train_df.project_subject_categories,\n",
    "                                                              'cat_')\n",
    "train_df = pd.concat([train_df,train_df_categories_dummies],axis=1)\n",
    "\n",
    "test_df.project_subject_categories = clean_categories(test_df.project_subject_categories)\n",
    "test_df_categories_dummies = get_dummies_from_series_of_lists(test_df.project_subject_categories,\n",
    "                                                             'cat_')\n",
    "test_df = pd.concat([test_df,test_df_categories_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Subcategories into Dummy Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182080/182080 [00:00<00:00, 937889.30it/s]\n",
      "100%|██████████| 182080/182080 [9:47:22<00:00,  2.77it/s]\n",
      "100%|██████████| 78035/78035 [00:00<00:00, 940624.47it/s]\n",
      "100%|██████████| 78035/78035 [1:52:17<00:00,  5.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df.project_subject_subcategories = clean_categories(train_df.project_subject_subcategories)\n",
    "train_df_subcategories_dummies = get_dummies_from_series_of_lists(train_df.project_subject_subcategories,\n",
    "                                                                 'subcat_')\n",
    "train_df = pd.concat([train_df,train_df_subcategories_dummies],axis=1)\n",
    "\n",
    "test_df.project_subject_subcategories = clean_categories(test_df.project_subject_subcategories)\n",
    "test_df_subcategories_dummies = get_dummies_from_series_of_lists(test_df.project_subject_subcategories,\n",
    "                                                                'subcat_')\n",
    "test_df = pd.concat([test_df,test_df_subcategories_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns = test_df.columns.str.lower()\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "train_df.to_csv('Data/cleaned_train_df.csv', index=False)\n",
    "test_df.to_csv('Data/cleaned_test_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
